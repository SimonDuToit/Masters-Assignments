{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53783034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "d5973595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>SENTENCE_BOUNDARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Injongo</td>\n",
       "      <td>N09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ye-website</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yaseMzantsi</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afrika</td>\n",
       "      <td>N05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token                POS\n",
       "0               SENTENCE_BOUNDARY\n",
       "1      Injongo                N09\n",
       "2   ye-website                  V\n",
       "3  yaseMzantsi                LOC\n",
       "4       Afrika                N05"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process training data\n",
    "df = pd.read_excel('data/GOV-ZA.50000ParallelleEnWoorde.xh.pos.full.xls')\n",
    "df = df[df.POS != 'PUNCT'].fillna('SENTENCE_BOUNDARY')\n",
    "data = [{'Token':'', 'POS':'SENTENCE_BOUNDARY'}]\n",
    "df = pd.concat([pd.DataFrame(data), df], ignore_index=True).reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "227893f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7771.8"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "40338ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation sets\n",
    "train = df.iloc[7778:].reset_index()\n",
    "validation = df.iloc[:7779].reset_index()\n",
    "\n",
    "# get tags and vocabulary\n",
    "states = train.POS.unique()\n",
    "vocab = train.Token.unique()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "e71531fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train HMM\n",
    "\n",
    "transitions = {}\n",
    "emissions = {}\n",
    "discount = 0.1\n",
    "trans_discount = 0.5\n",
    "discount_totals = {}\n",
    "trans_discount_totals = {}\n",
    "POS_counts = {}\n",
    "for i in range(1, len(train)):\n",
    "    key = train.POS[i]\n",
    "    POS_counts[key] = POS_counts.setdefault(key, 0) + 1      \n",
    "    key = (train.POS[i], train.POS[i-1])\n",
    "    transitions[key] = transitions.setdefault(key, 0) + 1\n",
    "    if train.POS[i] != 'SENTENCE_BOUNDARY':\n",
    "        key = (train.Token[i], train.POS[i])\n",
    "        emissions[key] = emissions.setdefault(key, 0) + 1\n",
    "\n",
    "# Normalize and smooth transition probabilities\n",
    "for key in list(transitions.keys()):\n",
    "    transitions[key] = (transitions[key]-trans_discount) / POS_counts[key[1]]\n",
    "    trans_discount_totals[key[1]] = trans_discount_totals.setdefault(key[1], 0) + trans_discount\n",
    "    \n",
    "for key in list(trans_discount_totals.keys()):\n",
    "    trans_discount_totals[key] = trans_discount_totals[key] / POS_counts[key]\n",
    "    \n",
    "unseen_counts = {}\n",
    "unseen_keys = []\n",
    "for s1 in states:\n",
    "    for s2 in states:\n",
    "        key = (s1, s2)\n",
    "        if key not in transitions:\n",
    "            transitions[key] = trans_discount_totals[s2]\n",
    "            unseen_counts[s2] = unseen_counts.setdefault(s2, 0) + 1\n",
    "            unseen_keys += [key]\n",
    "\n",
    "for key in unseen_keys:\n",
    "    transitions[key] = transitions[key] / unseen_counts[key[1]]\n",
    "\n",
    "# Normalize emission probabilities\n",
    "for key in list(emissions.keys()):\n",
    "    emissions[key] = (emissions[key] - discount) / POS_counts[key[1]]\n",
    "    discount_totals[key[1]] = discount_totals.setdefault(key[1], 0) + discount\n",
    "    \n",
    "for key in list(discount_totals.keys()):\n",
    "    discount_totals[key] = discount_totals[key] / POS_counts[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "26b3a7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check transition probablities\n",
    "pos_sum = 0\n",
    "for key in transitions:  \n",
    "    if key[1] == 'N05':\n",
    "        pos_sum += transitions[key]\n",
    "np.round(pos_sum, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "240fac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute discount smoothing\n",
    "def smooth(df, data):\n",
    "    smoothed = copy.deepcopy(df)\n",
    "    data_vocab = data.Token.unique()[1:]\n",
    "    full_vocab = np.unique(np.concatenate((vocab, data_vocab)))\n",
    "    unseen_counts = {}\n",
    "    unseen_keys = []\n",
    "    for s in states[1:]:\n",
    "        for w in full_vocab:\n",
    "            key = (w, s)\n",
    "            if key not in smoothed:\n",
    "                smoothed[key] = discount_totals[s]\n",
    "                unseen_counts[s] = unseen_counts.setdefault(s, 0) + 1\n",
    "                unseen_keys += [key]\n",
    "                \n",
    "    for key in unseen_keys:\n",
    "        smoothed[key] = smoothed[key] / unseen_counts[key[1]]\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "d3b74527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test data\n",
    "df = pd.read_excel('data/GOV-ZA.Toetsteks.5000ParallelleEnWoorde.xh.pos.full.xls')\n",
    "df = df[df.POS != 'PUNCT'].fillna('SENTENCE_BOUNDARY').reset_index(drop = True)\n",
    "test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "02bdfe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smooth emission probablities over validation / test set\n",
    "\n",
    "#target = validation\n",
    "target = test\n",
    "\n",
    "smoothed = smooth(emissions, target)\n",
    "\n",
    "# check emission probabilities\n",
    "pos_sum = 0\n",
    "for key in smoothed:  \n",
    "    if key[1] == 'N05':\n",
    "        pos_sum += smoothed[key]\n",
    "np.round(pos_sum, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "7ee299bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transition matrix\n",
    "A = np.zeros((len(states), len(states)))\n",
    "for i in range(len(states)):\n",
    "    for j in range(len(states)):\n",
    "        key = (states[i], states[j])\n",
    "        if key in transitions:\n",
    "            A[i,j] = transitions[key]\n",
    "        else:\n",
    "            A[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "4e45c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbi tagging for one sentence\n",
    "def viterbi(data):   \n",
    "    # initialization\n",
    "    gammas = [np.zeros(len(states)-1)]\n",
    "    psis = [[]]\n",
    "    token = data[0]\n",
    "    for s in range(1, len(states)):    \n",
    "        gammas[0][s-1] = np.log(smoothed[(token, states[s])]) + np.log(A[s,0])\n",
    "        \n",
    "    # recursive step\n",
    "    for i in range(1, len(data)):\n",
    "        token = data[i]\n",
    "        gammas += [np.zeros(len(states)-1)]\n",
    "        psis += [np.zeros(len(states)-1, dtype = int)]\n",
    "        for s in range(1, len(states)): \n",
    "            gammas[i][s-1] = np.log(smoothed[(token, states[s])]) + np.max(np.log(A[s,1:]) + gammas[i-1])\n",
    "            psis[i][s-1] = np.argmax(np.log(A[s,1:]) + gammas[i-1])\n",
    "            \n",
    "    # termination\n",
    "    z = np.argmax(np.log(A[0,1:]) + gammas[len(data)-1])\n",
    "    \n",
    "    # backtracking\n",
    "    sequence = [z+1]\n",
    "    for i in range(1, len(data)):\n",
    "        sequence += [psis[len(data)-i][sequence[i-1]]+1]\n",
    "    \n",
    "    sequence.reverse()\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "5f640de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910487288135594"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use HMM to tag data\n",
    "row = 0\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "while row < len(target):\n",
    "    \n",
    "    # split into sentences\n",
    "    sentence = []\n",
    "    while target.POS[row] != 'SENTENCE_BOUNDARY':\n",
    "        sentence += [target.Token[row]]\n",
    "        labels += [target.POS[row]]\n",
    "        row += 1\n",
    "    if sentence != []:\n",
    "        # tag sentence\n",
    "        predictions += viterbi(sentence)\n",
    "    row += 1\n",
    "    \n",
    "# compute accuracy\n",
    "(np.asarray([states[i] for i in predictions]) == np.asarray(labels)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
