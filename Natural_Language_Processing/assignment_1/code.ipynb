{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ce5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d3353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(file):\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        paragraphs = f.readlines()\n",
    "        \n",
    "    sentences = []\n",
    "    for p in paragraphs:\n",
    "         sentences += re.split('\\. |\\! \\? ', p)\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = re.sub('\\.', ' ', sentences[i])\n",
    "        sentences[i] = sentences[i].lower()\n",
    "        sentences[i] = unicodedata.normalize('NFD', sentences[i])\n",
    "        sentences[i] = re.sub('[^a-z0 ]', '', sentences[i])\n",
    "        sentences[i] = sentences[i].strip()\n",
    "        #sentences[i] = re.sub('(?<=0)[^0]{1}', '\\1 ', sentences[i])\n",
    "       \n",
    "    sentences = [s for s in sentences if s]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604d312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5820"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = normalize_text('data/train.en.txt')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73427862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(sentences, discount):\n",
    "    \n",
    "    characters = list(set(''.join(sentences)))\n",
    "    \n",
    "    for i, s in enumerate(sentences):\n",
    "        sentences[i] = '[[' + s + ']'  \n",
    "\n",
    "    trigrams = {}\n",
    "    s = sentences[0]\n",
    "    for c1 in (characters + ['[']):\n",
    "        for c2 in characters + ['['] + [']'] :\n",
    "            for c3 in (characters + [']']):\n",
    "                trigrams[c1+c2+c3] = 0\n",
    "\n",
    "    n_trigrams = 0\n",
    "    for s in sentences:\n",
    "        for i in range(len(s)-2):\n",
    "            trigram = s[i:i+3]\n",
    "            if trigrams[trigram] == 0:\n",
    "                n_trigrams += 1\n",
    "            trigrams[trigram] += 1            \n",
    "\n",
    "    charity = discount * n_trigrams / (len(trigrams)-n_trigrams)\n",
    "    for trigram, count in trigrams.items():\n",
    "\n",
    "        if count == 0:\n",
    "            trigrams[trigram] = charity\n",
    "        else:\n",
    "            trigrams[trigram] -= discount\n",
    "            \n",
    "    bigrams = {}\n",
    "    for trigram, count in trigrams.items():\n",
    "        bigram = trigram[:2]\n",
    "        if bigram in bigrams:\n",
    "            bigrams[bigram] += count\n",
    "        else:\n",
    "            bigrams[bigram] = count\n",
    "            \n",
    "    return (trigrams, bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "719ba11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model):\n",
    "    trigrams, bigrams = model\n",
    "    gen = '[['\n",
    "    while gen[-1] != ']':\n",
    "        filtered_trigrams = {}\n",
    "        for trigram, count in trigrams.items():\n",
    "            if trigram[0:2] == gen[-2:]:\n",
    "                filtered_trigrams[trigram] = count\n",
    "        chars = [k[-1] for k in filtered_trigrams.keys()]\n",
    "        values = np.asarray(list(filtered_trigrams.values()))\n",
    "        gen += np.random.choice(chars, p=values/bigrams[gen[-2:]])\n",
    "    gen = gen[2:-1]\n",
    "    print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43bb993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, sentences):\n",
    "    trigrams, bigrams = model\n",
    "    \n",
    "    P = 0\n",
    "    for s in sentences:\n",
    "        for i in range(2, len(s)):\n",
    "            P += np.log2(trigrams[s[i-2:i+1]]/bigrams[s[i-2:i]])\n",
    "    T = len(''.join(sentences))\n",
    "    return np.exp2((-1/T)*P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f09ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_validation(file):\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()        \n",
    "    sentences = []\n",
    "    for l in lines:\n",
    "        sentences += ['[['+l[:-2]+']']\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f6d3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model\n",
    "model = make_model(normalize_text('data/train.en.txt'), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c02a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.68113,\n",
       " 'th ': 0.09821,\n",
       " 'tha': 0.08313,\n",
       " 'thi': 0.04468,\n",
       " 'tho': 0.03815,\n",
       " 'thr': 0.03384,\n",
       " 'thn': 0.00455,\n",
       " 'ths': 0.00407,\n",
       " 'th]': 0.00293,\n",
       " 'thu': 0.00232,\n",
       " 'thy': 0.00192,\n",
       " 'thc': 0.00192,\n",
       " 'thl': 0.00091,\n",
       " 'thw': 0.00064,\n",
       " 'thd': 0.00057,\n",
       " 'thm': 0.00051,\n",
       " 'tht': 0.00024,\n",
       " 'thp': 0.0001,\n",
       " 'thf': 3e-05,\n",
       " 'thb': 3e-05,\n",
       " 'thh': 3e-05,\n",
       " 'thg': 1e-05,\n",
       " 'thx': 1e-05,\n",
       " 'thq': 1e-05,\n",
       " 'thj': 1e-05,\n",
       " 'th0': 1e-05,\n",
       " 'thk': 1e-05,\n",
       " 'thz': 1e-05,\n",
       " 'thv': 1e-05}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show conditional probabilities for trigrams starting in 'th'\n",
    "filtered_trigrams = {}\n",
    "for trigram, count in model[0].items():\n",
    "    if trigram[0:2] == 'th':\n",
    "        filtered_trigrams[trigram] = np.round(count / model[1]['th'], 5)\n",
    "dict(sorted(filtered_trigrams.items(), key=lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4bf31c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soodersosstrastrop volstitste para relnalanaan delsen die omgcds nap die genent not die bes let dinge dier n 0 hoeksie pubkom nolke laantigsfis d bacoeie ste terned\n"
     ]
    }
   ],
   "source": [
    "generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7045114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afrikaans: 27.62\n",
      "English: 18.64\n",
      "Dutch: 27.14\n",
      "isiXhosa: 9.34\n",
      "isiZulu: 8.37\n"
     ]
    }
   ],
   "source": [
    "# Perplexities\n",
    "files = ['data/val.af.txt', 'data/val.en.txt', 'data/val.nl.txt',\\\n",
    "         'data/val.xh.txt', 'data/val.zu.txt']  \n",
    "languages = ['Afrikaans', 'English', 'Dutch', 'isiXhosa', 'isiZulu']\n",
    "perplexities = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(languages[i] +': '+ str(np.round(perplexity(model, format_validation(files[i])),2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89e52ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha tuning\n",
    "train_files = ['data/train.af.txt', 'data/train.en.txt', 'data/train.nl.txt',\\\n",
    "               'data/train.xh.txt', 'data/train.zu.txt']\n",
    "\n",
    "val_files = ['data/val.af.txt', 'data/val.en.txt', 'data/val.nl.txt',\\\n",
    "             'data/val.xh.txt', 'data/val.zu.txt']  \n",
    "models = []\n",
    "best_discounts = []\n",
    "for i in range(5):\n",
    "    min_p = 999\n",
    "    for discount in np.arange(0.1, 1.0, 0.1):\n",
    "        model = make_model(normalize_text(train_files[i]), discount)\n",
    "        p = perplexity(model, format_validation(val_files[i]))\n",
    "        if p < min_p:\n",
    "            min_p = p\n",
    "            best_model = model\n",
    "            best_discount = discount\n",
    "    models += [best_model]\n",
    "    best_discounts += [best_discount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b53433a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4, 0.5, 0.4, 0.4, 0.5]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c6927fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afrikaans: 19.490588251071255\n",
      "English: 7.5738326934989795\n",
      "Dutch: 19.344719613124187\n",
      "isiXhosa: 41.106944956814445\n",
      "isiZulu: 44.45049600247382\n"
     ]
    }
   ],
   "source": [
    "# Perplexities (tuned models)\n",
    "files = ['data/val.af.txt', 'data/val.en.txt', 'data/val.nl.txt',\\\n",
    "         'data/val.xh.txt', 'data/val.zu.txt']  \n",
    "languages = ['Afrikaans', 'English', 'Dutch', 'isiXhosa', 'isiZulu']\n",
    "perplexities = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(languages[i] +': '+ str(perplexity(models[1], format_validation(files[i])))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "40702672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.60000000000001% accuracy on test data\n"
     ]
    }
   ],
   "source": [
    "# format\n",
    "test_file = 'data/test.lid.txt'\n",
    "with open(test_file, encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "labels = []\n",
    "sentences = []\n",
    "languages = ['af', 'en', 'nl', 'xh', 'zu']\n",
    "for l in lines:\n",
    "    labels += [languages.index(l[:2])]  \n",
    "    sentences += ['[['+l[3:-2]+']']\n",
    "\n",
    "# classify\n",
    "classes = []\n",
    "for s in sentences:  \n",
    "    if len(s) == 0:\n",
    "        continue\n",
    "    perplexities = []\n",
    "    for m in models:\n",
    "        perplexities += [perplexity(m, [s])]\n",
    "    classes += [np.argmin(perplexities)]\n",
    "acc = (np.asarray(labels) == np.asarray(classes)).mean()\n",
    "print (str(acc*100) + '% accuracy on test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fb588662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 [[umbhalo]\n",
      "2 0 [[zuidafrika]\n",
      "4 3 [[brough amamormon labo ababebhapathizwa 000 000 ukuqothulwa kwesizwe izisulu kwakhe abangu eshukunyiswa uthando nesihe futhi abazange baqonde isenzo sabo kungase kubacasule amajuda]\n",
      "4 3 [[iquran ayikaze ikhulume ngoyise kajona kodwa isiko lamasulumane lifundisa ukuthi ujona wayevela esizweni sakwabenjamini nokuthi ubaba wakhe kwakungu amittai]\n",
      "2 0 [[bevolking]\n",
      "4 3 [[ukubaluleka kanye neziqu eziyisisekelo]\n",
      "4 3 [[ukulungiselela]\n",
      "4 3 [[kodwake ukusebenzela imishini akudingeki ukuze uqhubeke ubulungu besonto]\n",
      "4 0 [[amaallergener]\n",
      "4 3 [[emashumini amabili edlule isonto lds likhuphule ikhwelo lalo lokuba izithunywa zevangeli esezikhulile]\n",
      "4 3 [[okukhulu kunakho konke lokhu yi mormonism ejwayelekile echazwe ubuholi bethe church of jesus christ of latterday saints lds church ukunyakaza okubili okubanzi ngaphandle kwamamormonism ajwayelekile yi mormon basicism kanye neliberal reformist mormonism]\n",
      "4 3 [[smith]\n",
      "0 2 [[hewiston]\n",
      "1 0 [[rfc 0000 p]\n",
      "3 4 [[ulalise endleleni]\n",
      "2 0 [[monsels verliet in 0000 het surinaamse leger]\n",
      "4 3 [[ku 0000 iyfm yethule iwebhusayithi yayo esemthethweni yworld i y eseyfm imele intsha ngoba lo msakazo ubudalelwe ikakhulukazi intsha emnyama]\n",
      "0 1 [[andre p]\n",
      "4 3 [[ukungcola okungapheli kwemvelo]\n",
      "3 4 [[waphinda waba ngumlawuli womculo kwinkundla yasedresden ngo 0000 kwinkonzo kafrederick augustus ii]\n",
      "4 3 [[ngaphakathi kwesonto lelds ubumsulwa busho okungaphezu kokugwema ukuya ocansini kusho ukuhlanzeka ngokokuziphatha emicabangweni emazwini nasezenzweni kusho nokuthi ubudlelwane bobulili buvunyelwe kuphela phakathi kwendoda nenkosikazi]\n",
      "0 2 [[die nederlands marienekorps se kaserne is in rotterdam doorn suffisant op curaao en savaneta op aruba]\n",
      "3 4 [[umotlaong livela tanci kumgodeli]\n",
      "2 1 [[fraters]\n",
      "4 3 [[ujoseph smith wathi ijerusalema elisha leminyaka eyinkulungwane lalizokwakhiwa emelika i 00 th article of faith]\n",
      "3 4 [[makube igama likamgodeli laaqalela kweli thuba ukuduma]\n",
      "4 3 [[amakuraysh athumele inceku yabo u addas ukuthi bayomsebenzela amagilebhisi ukuze baziphilise]\n",
      "0 4 [[impak]\n",
      "4 3 [[ukungezwani komzimba kungavela ekungeniseni ukudla kwasolwandle noma ngokuphefumula umusi ngokulungiselela noma ekuphekeni kwasolwandle ukusabela okweqile kwasolwandle kokungezwani komzimba neanaphylaxis isimo esiphuthumayo esidinga ukunakwa ngokushesha]\n",
      "1 4 [[tls handshake]\n",
      "3 4 [[my name is mthawelanga]\n",
      "0 2 [[ontwikkeling]\n",
      "4 2 [[eislam]\n",
      "3 4 [[namhla bezingekho dlelweni linye nezabanye]\n",
      "0 2 [[i]\n",
      "4 3 [[imidlalo]\n",
      "4 3 [[quran]\n",
      "3 4 [[udilima uzele unamba]\n",
      "4 3 [[izinzuzo zezempilo]\n",
      "4 3 [[incwadi yezithunywa zevangeli]\n",
      "4 3 [[ujona noma ujonas loweralpha 0 indodana ka amittai ungumprofethi ebhayibhelini lesiheberu nasequran ovela egathhepher yombuso wasenyakatho wakwaisrayeli cishe ngekhulu lesi 0 bce ujona unendima eyinhloko ye incwadi kajona okuyinto imininingwane ukunqikaza ekukuletheleni nkulunkulu ukwahlulela ka emzini inineve bese kwakhe okwalandela siqala begrudged ukubuya mission saphezulu ngemva kokuba yagwinywa isilwane esikhulu sasolwandle]\n",
      "4 3 [[ukufundisa kwentsha]\n",
      "4 3 [[ukuhlukana ngokwenkolo]\n",
      "4 3 [[ukubaluleka]\n",
      "4 3 [[amahadiths]\n",
      "1 4 [[]\n",
      "4 3 [[lokho akulula ukumelana nakho]\n",
      "4 3 [[ubungqingili]\n",
      "4 3 [[ebujudeni]\n",
      "4 3 [[ukugqoka nokuzilungisa]\n",
      "3 4 [[vi]\n",
      "4 3 [[iphinde lifundisa ukuthi wonke umuntu unelungelo lokuthola isambulo siqu mayelana yakhe nobuphathi ubuholi umthwalo ngakhoke abazali bangathola ugqozi oluvela kunkulunkulu ekukhuliseni imindeni yabo abantu ngabanye bangathola ugqozi olungcwele lokubasiza bahlangabezane nezinselelo zabo abaphathi bebandla bangathola isambulo kulabo ababasebenzelayo]\n",
      "4 3 [[kube khona ukuphikisana okubandakanya amaqembu amajuda abona isenzo sezinto ezithile zemormonism njengezinyanyekayo ngama 0000 s amaqembu amajuda aphikisana kakhulu nomkhuba welds wokubhabhadisela abafileyo egameni lezisulu ezingamajuda zokuqothulwa kwesizwe kanye namajuda jikelele ngokusho lds isonto igunya jikelele monte j]\n",
      "4 3 [[umthetho wobumsulwa ungenye yezivumelwano amalungu esonto lelds athembisa ngesifungo ukuwagcina ngesikhathi somcimbi wethempeli]\n",
      "3 4 [[ekuvukeni kwakhe uthabathe ulugxa naanko enyathela umhlaba amabombo ewabhekisa ngasemathambekeni]\n",
      "3 4 [[ubach wazalelwa eeisenach ngo 0000]\n",
      "0 2 [[zijner majesteits his majestys wanneer n koning op die troon is en hr ms]\n",
      "4 3 [[kodwake ngaphezu kokuthi ungumthombo wamandla umnikelo wokudla wezinhlanzi ubalulekile ngokwezinga eliphezulu amaprotheni ezilwane agaywe kalula futhi ikakhulukazi ekulweni nokushoda kwemicronutrient]\n",
      "4 3 [[kumormonism isimiso isiko lenkolo elibaluleke ngokukhethekile imvamisa lifaka ukwakheka kwesivumelwano nonkulunkulu]\n",
      "3 4 [[izalelwe emenkhoaneng kwamkhatshane]\n",
      "4 3 [[imibono yenkolo]\n",
      "4 3 [[smith wakhipha manifesto okwesibili ngemva kwalokho esikhathini elaqala inqubomgomo lds church excommunicate labo amalungu esonto angena noma solemnized nabantu abasanda kushada esithenjini]\n",
      "4 3 [[imibono yangemva kwebhayibheli]\n",
      "0 2 [[sport]\n",
      "1 2 [[optical heterodyning]\n",
      "4 3 [[scott uchaze wathi ohlukumezekile kumele enze konke okusemandleni akhe ukunqanda ukuhlukunyezwa esikhathini esiningi isisulu simsulwa ngenxa yokukhubazeka ngokwesaba noma ngamandla noma igunya lowonile esikhathini esithile noma kunjalo inkosi ingase ishukumise isisulu ukuba sibone izinga elithile lokuzibophezela ekuhlukunyezweni umholi wakho wobupristi uzosiza ukuhlola umthwalo wakho wemfanelo ukuze uma kudingeka kubhekwane nawo]\n",
      "4 3 [[amazinga ajwayelekile]\n",
      "3 4 [[abakwamgodeli babephethe umphako wotshongo abakwantsane abakatonyane babephethe umgquba osiliweyo uyelele kakhulu etshongweni ngenkangeleko]\n",
      "4 3 [[enye ingu 0000 yencwajana yemikhombandlela yentsha yesonto eyayithi inkosi iyakwenqabela ngokukhethekile]\n",
      "4 3 [[wabe esebuza ukuthi umuhammad wazi kanjani ngale ndoda]\n",
      "2 4 [[europa]\n",
      "4 3 [[ukuqeqesha]\n",
      "4 3 [[emcimbini wokunikezela]\n",
      "0 2 [[admiraal stephen b]\n",
      "3 4 [[iiriphabliki]\n",
      "3 4 [[uhina uzele usampu kwindlu enkulu nosentile nofeni]\n",
      "4 3 [[ukushaya indlwabu]\n",
      "4 3 [[amabiotoxin]\n",
      "4 3 [[izimiso zenziwa ngegunya lobupristi kanye nangegama likajesu kristu leli gama linencazelo ecishe ifane naleyo yegama elithi isakramente kwamanye amahlelo obukristu]\n",
      "4 3 [[ukugqoka ngendlela engenasizotha akukhona ukwephula umthetho wobumsulwa kepha isizotha sithuthukisa ubumsulwa]\n",
      "4 3 [[kufaka ukweqa okubanzi]\n",
      "3 4 [[ngubani igama lakho]\n",
      "2 0 [[flora en fauna]\n",
      "3 1 [[ifederalism]\n"
     ]
    }
   ],
   "source": [
    "# show mistakes\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] != classes[i]:\n",
    "        print(labels[i], classes[i], sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aa3e53d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "49\n",
      "74\n",
      "99\n",
      "24\n",
      "49\n",
      "74\n",
      "99\n",
      "24\n",
      "49\n",
      "74\n",
      "99\n",
      "24\n",
      "49\n",
      "74\n",
      "99\n",
      "24\n",
      "49\n",
      "74\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# byte-pair encoding\n",
    "token_sets = []\n",
    "for file in train_files:\n",
    "    sentences = normalize_text(file)\n",
    "    tokens = []\n",
    "\n",
    "    for iteration in range(100):\n",
    "        merges = {}\n",
    "\n",
    "        for i in range(len(sentences)):\n",
    "            sentences[i] = [*sentences[i]]\n",
    "\n",
    "        for s in sentences:\n",
    "            for t in range(len(s)-1):\n",
    "                merge = ''.join(s[t:t+2])\n",
    "                if merge in merges:\n",
    "                    merges[merge] += 1\n",
    "                else:\n",
    "                    merges[merge] = 1\n",
    "\n",
    "        new_token = max(merges, key=merges.get)\n",
    "        tokens += [new_token]\n",
    "\n",
    "        for s in sentences:\n",
    "            for t in range(len(s)-1):     \n",
    "                if ''.join(s[t:t+2]) == new_token:\n",
    "                    s[t] = new_token\n",
    "                    s.pop(t+1)\n",
    "\n",
    "        if (iteration % 25 == 24):\n",
    "            print(iteration)\n",
    "    token_sets += [tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a7d4e669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of common subword units\n",
    "len(list(set(token_sets[3]) & set(token_sets[4])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
